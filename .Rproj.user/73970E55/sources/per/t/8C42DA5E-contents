---
title: "Devoir Élections"
author: "Gabriel Houdry--Bohême, Adem Bensalem, Milan Soragna, Hector Ménétrier, Serigne
  Massamba Guèye"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
## I. Présentation de la base de données 

La base de données choisie est celle des résultats du premier tour des élections présidentielles françaises de 2022.
Elle contient pour chaque commune française le résultat de votes de chaque candidat, avec les votes blancs et les abstensions.
Afin de l'analyser, chargeons d'abord les bibliothèques nécessaires.
```{r}
library(tidyverse)
library(stringr)
library(stringi)
library(readxl)
library(dplyr)
library(MASS)

```

La base de donnée est importée par la commande suivante.
```{r}
# Récupération des résultats
dataset <- read_xlsx("dataset_elections.xlsx")
```

Nous avons initialement fait des tests dans le fichier main.R, avant de déplacer tout le code dans Devoir1.Rmd.
## II. Analyse des votes par candidat

Ensuite, nous devons effectuer un nettoyage des données. En effet, toutes les informations ne sont pas utiles pour la visualisation, et nous souhaitons les mettre sous une forme plus simple à analyser.
Ici, pour une visualisation sous forme de carte, nous regroupons les résultats par département.
```{r}
# Nettoyage des données et aggrégation des résultats
dataset_cleaned <- dataset %>%
  group_by(`Code du département`, `Libellé du département`) %>%
  summarise(total_votes = sum(Exprimés), 
            total_blancs = sum(Blancs),
            pourcentage_blanc = total_blancs / sum(Votants) * 100, 
            total_abs = sum(as.numeric(Abstentions)), 
            pourcentage_abs = total_abs / sum(as.numeric(Inscrits))* 100,
            total_arthaud = sum(VoixArthaud), 
            pourcentage_arthaud = total_arthaud / total_votes * 100,
            total_roussel = sum(VoixRoussel),
            pourcentage_roussel = total_roussel / total_votes * 100,
            total_macron = sum(VoixMacron),
            pourcentage_macron = total_macron / total_votes * 100,
            total_lassalle = sum(VoixLassalle),
            pourcentage_lassalle = total_lassalle / total_votes * 100,
            total_lepen = sum(VoixLePen),
            pourcentage_lepen = total_lepen / total_votes * 100,
            total_zemmour = sum(VoixZemmour),
            pourcentage_zemmour = total_zemmour / total_votes * 100,
            total_melenchon = sum(VoixMelenchon),
            pourcentage_melenchon = total_melenchon / total_votes * 100,
            total_hidalgo = sum(VoixHidalgo),
            pourcentage_hidalgo = total_hidalgo / total_votes * 100,
            total_jadot = sum(VoixJadot),
            pourcentage_jadot = total_jadot / total_votes * 100,
            total_pecresse = sum(VoixPecresse),
            pourcentage_pecresse = total_pecresse / total_votes * 100,
            total_poutou = sum(VoixPoutou),
            pourcentage_poutou = total_poutou / total_votes * 100,
            total_dupontaignan = sum(VoixDupontAignan),
            pourcentage_dupontaignan = total_dupontaignan / total_votes * 100)
```

Nous pouvons désormais observer la moyenne de votes par département pour chaque candidat.
```{r moyenne, fig.align='center'}
#Moyenne de vote de chaque candidat par département
moy_votes = mean(dataset_cleaned$total_votes)
moy_abs = mean(dataset_cleaned$total_abs)
moy_blanc = mean(dataset_cleaned$total_blancs)
moy_votes_candidat <- c("N. Arthaud" = mean(dataset_cleaned$total_arthaud), 
                       "P. Poutou" = mean(dataset_cleaned$total_poutou),
                       "F. Roussel" = mean(dataset_cleaned$total_roussel),
                       "J-L. Mélenchon" = mean(dataset_cleaned$total_melenchon),
                       "A. Hidalgo" = mean(dataset_cleaned$total_hidalgo),
                       "Y. Jadot" = mean(dataset_cleaned$total_jadot),
                       "E. Macron" = mean(dataset_cleaned$total_macron), 
                       "J. Lassalle" = mean(dataset_cleaned$total_lassalle),
                       "V. Pecresse" = mean(dataset_cleaned$total_pecresse),
                       "M. Le Pen" = mean(dataset_cleaned$total_lepen),
                       "N. Dupont-Aignan" = mean(dataset_cleaned$total_dupontaignan),
                       "É. Zemmour" = mean(dataset_cleaned$total_zemmour))
#Tri des candidats par moyenne de votes.
sorted_avg_votes <- sort(moy_votes_candidat, decreasing = TRUE)
options(scipen = 999)
# Création du graphe
barplot(sorted_avg_votes, 
        main = "Moyenne de votes par candidat par département",
        xlab = "Candidats",
        ylab = "Moyenne de votes par département",
        col = "skyblue",
        ylim = c(0, max(sorted_avg_votes) * 1.1),
        las = 2)
```

On peut également représenter les pourcentages d'obtention de vote des candidats grâce à un diagramme circulaire.

```{r}
# Couleur pour les candidats
candidate_colors <- c("N. Arthaud" = "red4", 
                      "P. Poutou" = "red3",
                      "F. Roussel" = "red2",
                      "J-L. Mélenchon" = "tomato2",
                      "A. Hidalgo" = "salmon2",
                      "Y. Jadot" = "springgreen4",
                      "E. Macron" = "goldenrod1", 
                      "J. Lassalle" = "lightblue",
                      "V. Pecresse" = "royalblue1",
                      "M. Le Pen" = "blue2",
                      "N. Dupont-Aignan" = "blue3",
                      "É. Zemmour" = "navyblue")

#pourcentage
total_votes = sum(dataset_cleaned$total_votes)
candidate_pourcentage <- c("N. Arthaud" = sum(dataset_cleaned$total_arthaud)/total_votes*100,
                           "P. Poutou" = sum(dataset_cleaned$total_poutou)/total_votes*100,
                           "F. Roussel" = sum(dataset_cleaned$total_roussel)/total_votes*100,
                           "J-L. Mélenchon" = sum(dataset_cleaned$total_melenchon)/total_votes*100,
                           "A. Hidalgo" = sum(dataset_cleaned$total_hidalgo)/total_votes*100,
                           "Y. Jadot" = sum(dataset_cleaned$total_jadot)/total_votes*100,
                           "E. Macron" = sum(dataset_cleaned$total_macron)/total_votes*100,
                           "J. Lassalle" = sum(dataset_cleaned$total_lassalle)/total_votes*100,
                           "V. Pecresse" = sum(dataset_cleaned$total_pecresse)/total_votes*100,
                           "M. Le Pen" = sum(dataset_cleaned$total_lepen)/total_votes*100,
                           "N. Dupont-Aignan" = sum(dataset_cleaned$total_dupontaignan)/total_votes*100,
                           "É. Zemmour" = sum(dataset_cleaned$total_zemmour)/total_votes*100)

# Données
noms_candidats <- names(sorted_avg_votes)
moyennes_votes <- unname(sorted_avg_votes)


# Création du diagramme circulaire
par(pty = "m", mfrow = c(1, 1), mar = c(2, 2, 2, 2))

plot.new()

pie(moyennes_votes, 
    labels = paste(round(candidate_pourcentage[noms_candidats]),"%"),
    main = "Pourcentage des votes par candidat", 
    col = candidate_colors[noms_candidats],
    cex = 0.6)

legend("right", 
       legend = noms_candidats, 
       fill = candidate_colors[noms_candidats], 
       title = "Candidats", 
       cex = 0.6)
```



Nous pouvons également regarder l'étendue des données que nous venons d'obtenir.

```{r}
etendue = max(moy_votes_candidat) - min(moy_votes_candidat)
print(etendue)
```
En moyenne par région, il y a environ 328 345 votants, 119 852 abstentions et 5080 vote blancs.
L'étendue des votes entre les candidats est d'environ 89 588 votes.

## III. Cartographie des résultats

Tout d'abord, nous allons nous intéresser principalement à la France métropolitaine. 
Pour ce faire, il suffit de filtrer les départements.
```{r}
# Changement de noms de départements
names(dataset_cleaned)[2] <- "region"
dataset_cleaned$region <- stri_trans_general(dataset_cleaned$region, "Latin-ASCII") %>%
  str_replace_all("Cote-d'Or", "Cote-Dor") %>%
  str_replace_all("Cotes-d'Armor", "Cotes-Darmor") %>%
  str_replace_all("Corse-du-Sud", "Corse du Sud") %>%
  str_replace_all("Val-d'Oise", "Val-Doise") %>%
  str_replace_all("Corse-du-Sud", "Corse du Sud")

# Récupération de la carte de France
map <- map_data("france")

# Filtrage des départements pour ne garder que la France métropolitaine
dataset_cleaned_filtered <- dataset_cleaned %>%
  filter(region %in% map$region)

# Fusion avec les données de la carte
result_map <- left_join(x = map[,-6], y = dataset_cleaned_filtered)
```

Ensuite, il faut trouver le candidat arrivé en tête dans chaque département

```{r}
# On cherche ici le candidat en tête dans chaque département
result_map <- result_map %>%
  rowwise() %>%
  mutate(candidat_gagnant = case_when(
    total_arthaud == max(total_arthaud, total_roussel, total_macron, 
                         total_lassalle, total_lepen, total_zemmour, 
                         total_melenchon, total_hidalgo, total_jadot, 
                         total_pecresse, total_poutou, total_dupontaignan) ~ "N. Arthaud",
    total_roussel == max(total_arthaud, total_roussel, total_macron, 
                         total_lassalle, total_lepen, total_zemmour, 
                         total_melenchon, total_hidalgo, total_jadot, 
                         total_pecresse, total_poutou, total_dupontaignan) ~ "F. Roussel",
    total_macron == max(total_arthaud, total_roussel, total_macron, 
                        total_lassalle, total_lepen, total_zemmour, 
                        total_melenchon, total_hidalgo, total_jadot, 
                        total_pecresse, total_poutou, total_dupontaignan) ~ "E. Macron",
    total_lassalle == max(total_arthaud, total_roussel, total_macron, 
                          total_lassalle, total_lepen, total_zemmour, 
                          total_melenchon, total_hidalgo, total_jadot, 
                          total_pecresse, total_poutou, total_dupontaignan) ~ "J. Lassalle",
    total_lepen == max(total_arthaud, total_roussel, total_macron, 
                       total_lassalle, total_lepen, total_zemmour, 
                       total_melenchon, total_hidalgo, total_jadot, 
                       total_pecresse, total_poutou, total_dupontaignan) ~ "M. Le Pen",
    total_zemmour == max(total_arthaud, total_roussel, total_macron, 
                         total_lassalle, total_lepen, total_zemmour, 
                         total_melenchon, total_hidalgo, total_jadot, 
                         total_pecresse, total_poutou, total_dupontaignan) ~ "É. Zemmour",
    total_melenchon == max(total_arthaud, total_roussel, total_macron, 
                           total_lassalle, total_lepen, total_zemmour, 
                           total_melenchon, total_hidalgo, total_jadot, 
                           total_pecresse, total_poutou, total_dupontaignan) ~ "J-L. Mélenchon",
    total_hidalgo == max(total_arthaud, total_roussel, total_macron, 
                         total_lassalle, total_lepen, total_zemmour, 
                         total_melenchon, total_hidalgo, total_jadot, 
                         total_pecresse, total_poutou, total_dupontaignan) ~ "A. Hidalgo",
    total_jadot == max(total_arthaud, total_roussel, total_macron, 
                       total_lassalle, total_lepen, total_zemmour, 
                       total_melenchon, total_hidalgo, total_jadot, 
                       total_pecresse, total_poutou, total_dupontaignan) ~ "Y. Jadot",
    total_pecresse == max(total_arthaud, total_roussel, total_macron, 
                          total_lassalle, total_lepen, total_zemmour, 
                          total_melenchon, total_hidalgo, total_jadot, 
                          total_pecresse, total_poutou, total_dupontaignan) ~ "V. Pécresse",
    total_poutou == max(total_arthaud, total_roussel, total_macron, 
                        total_lassalle, total_lepen, total_zemmour, 
                        total_melenchon, total_hidalgo, total_jadot, 
                        total_pecresse, total_poutou, total_dupontaignan) ~ "P. Poutou",
    total_dupontaignan == max(total_arthaud, total_roussel, total_macron, 
                              total_lassalle, total_lepen, total_zemmour, 
                              total_melenchon, total_hidalgo, total_jadot, 
                              total_pecresse, total_poutou, total_dupontaignan) ~ "N. Dupont-Aignan",
    TRUE ~ NA_character_
  ))
```

Nous pouvons désormais générer la carte.
D'abord, nous assignons une couleur à chaque candidat.
Ensuite, nous créons le thème de la carte qui sera générée à l'aide de ggplot.
```{r carte, fig.align='center'}
# Couleur pour les candidats
candidate_colors <- c("N. Arthaud" = "red4", 
                      "P. Poutou" = "red3",
                      "F. Roussel" = "red2",
                      "J-L. Mélenchon" = "tomato2",
                      "A. Hidalgo" = "salmon2",
                      "Y. Jadot" = "springgreen4",
                      "E. Macron" = "goldenrod1", 
                      "J. Lassalle" = "lightblue",
                      "V. Pecresse" = "royalblue1",
                      "M. Le Pen" = "blue2",
                      "N. Dupont-Aignan" = "blue3",
                      "É. Zemmour" = "navyblue")

# Apparence de la carte
map_theme <- theme(title = element_text(margin = margin(b = 20, r = 25)), # Ajustement des marges intérieures du titre
                   plot.title = element_text(margin = margin(b = 20, t = 20)), # Ajustement des marges intérieures du titre principal
                   plot.subtitle = element_text(margin = margin(b = 20)), # Ajustement des marges intérieures du sous-titre
                   axis.text.x=element_blank(),
                   axis.text.y=element_blank(),
                   axis.ticks=element_blank(),
                   axis.title.x=element_blank(),
                   axis.title.y=element_blank(),
                   panel.grid.major= element_blank(), 
                   panel.background= element_blank()) 

# Création de la carte
ggplot(result_map, aes(long, lat, group = group, fill = candidat_gagnant)) +
  geom_polygon() +
  geom_path(color = "white", size = 0.3) + # On ajoute la frontière entre les départements
  coord_map() +
  scale_fill_manual(values = candidate_colors, name = "Candidat arrivé en tête") +
  labs(x = "", 
       y = "", 
       title = "Candidat arrivé en tête par département au premier tour des présidentielles 2022", 
       subtitle = "Données via data.gouv") +
  map_theme
```

Grâce à cette carte, on peut observer quels candidats sont plus choisis par certains territoires. Par exemple, la région parisienne a en majoritairement choisi Jean-Luc Mélenchon, alors que la zone connue sous le nom de "diagonale du vide" a choisi Marine Le Pen. Emmanuel Macron reste en majorité sur tout le reste du pays.

# IV. Classification avec k-NN

Maintenant, nous allons utiliser l'algorithme k-NN pour classer les données en fonction des votes pour chaque candidat.

```{r}
library(class)

# Sélection des variables pour la prédiction
features <- c("total_votes", "total_blancs", "pourcentage_blanc", "total_abs", "pourcentage_abs", "total_arthaud", "pourcentage_arthaud", "total_roussel", "pourcentage_roussel", "total_macron", "pourcentage_macron", "total_lassalle", "pourcentage_lassalle", "total_lepen", "pourcentage_lepen", "total_zemmour", "pourcentage_zemmour", "total_melenchon", "pourcentage_melenchon", "total_hidalgo", "pourcentage_hidalgo", "total_jadot", "pourcentage_jadot", "total_pecresse", "pourcentage_pecresse", "total_poutou", "pourcentage_poutou", "total_dupontaignan", "pourcentage_dupontaignan")

# Création d'une nouvelle colonne 'candidat_gagnant' basée sur le pourcentage le plus élevé
dataset_cleaned$candidat_gagnant <- apply(dataset_cleaned[, grep("pourcentage_", names(dataset_cleaned))], 1, function(x) names(x)[which.max(x)])

# Séparation des données en ensembles d'entraînement et de test
set.seed(123)
train_indices <- sample(nrow(dataset_cleaned), nrow(dataset_cleaned) * 0.7)
train_data <- dataset_cleaned[train_indices, ]
test_data <- dataset_cleaned[-train_indices, ]

# Entraînement du modèle KNN
k <- 3
knn_model <- knn(train = train_data[, features], 
                 test = test_data[, features], 
                 cl = train_data$candidat_gagnant, 
                 k = k)

# Évaluation des performances
accuracy <- sum(knn_model == test_data$candidat_gagnant) / length(test_data$candidat_gagnant)
cat("Précision du modèle KNN :", round(accuracy * 100, 2), "%\n")

```
Dans cette section, nous avons utilisé l'algorithme k-NN pour classer les données en fonction des votes pour chaque candidat. La précision du modèle k-NN a été évaluée et affichée.

# V. Conclusion

Pour conclure, à partir des données récupérées sur le site du gouvernement français, nous avons pu nettoyer et extraire les données qui nous intéressaient pour générer plusieurs visualisations et appliquer des méthodes vues dans le cadre du cours. Une suite intéressante à ce projet serait d'associer ces résultats à d'autres données sur les territoires pour essayer de comprendre ce qui pourrait pousser la population à choisir des candidats, par exemple en étudiant la relation entre tel candidat et le taux de revenuw moyen.

# TP N°2

Afin d'aller plus loin dans cette analyse, nous avons décidé de rajouter deux jeux de données que nous allons croiser avec les résultats d'élections.
Nous avons choisi un jeu de données portant sur le crime par département, et un autre sur le taux de chômage par département.
Tout d'abord, nous devons les nettoyer pour pouvoir les utiliser correctement.

## I. Nettoyage des jeux de données

### a. Dataset sur les crimes
D'abord, nous ne gardons que les données métropolitaines. Il nous faut ensuite calculer pour chaque département et chaque année, le taux de crime par 1000 habitants. Enfin, pour utiliser les données plus facilement, nous utilisons les données du dataset utilisé pour créer la carte pour récupérer le nom de département, afin d'établir la relation entre les jeux de données
```{r}
library(stringr)

# Chargement du jeu de données
crime_data <- read_xlsx("dataset_crime.xlsx") 

# Exclusion des DOM TOM
crime_data_filtre <- crime_data %>%
  filter(!CodeDépartement %in% c(971, 972, 973, 974, 975, 976, "NA"))

# Ajout d'un zéro au début des codes de département (Pour avoir les mêmes que dans dataset_cleaned_filtered)
crime_data_filtre$CodeDépartement <- str_pad(crime_data_filtre$CodeDépartement, width = 2, side = "left", pad = "0")

# Récupération des crimes par département par année
crime_departement_annee <- crime_data_filtre %>%
  group_by(CodeDépartement, annee) %>%
  summarise(total_crimes = sum(faits))

# Ajout de la population par département par année
crime_departement_annee <- left_join(crime_departement_annee, 
                                     crime_data_filtre %>% 
                                       group_by(CodeDépartement, annee) %>% 
                                       summarise(Population = max(POP)),
                                     by = c("CodeDépartement", "annee"))

# Calcul du taux de criminalité par 1000 habitants pour chaque département chaque année
crime_departement_annee <- mutate(crime_departement_annee, taux_crime_par_1000 = round((total_crimes / as.numeric(Population)) * 1000, 2))

# Amélioration de l'affichage de l'année en ajoutant le préfixe 20 pour obtenir par exemple 2016
crime_departement_annee$annee <- as.numeric(paste0("20", crime_departement_annee$annee))

names(dataset_cleaned_filtered)[names(dataset_cleaned_filtered) == "Code du département"] <- "CodeDépartement"

# Correction des codes "2A" et "2B" dans dataset_cleaned_filtered
dataset_cleaned_filtered$CodeDépartement <- ifelse(dataset_cleaned_filtered$CodeDépartement %in% c("2A", "2B"), 
                                                   dataset_cleaned_filtered$CodeDépartement, 
                                                   str_pad(dataset_cleaned_filtered$CodeDépartement, width = 2, side = "left", pad = "0"))

# Jointure sur le code du département avec le dataset principal
crime_departement_annee <- left_join(crime_departement_annee, 
                                     dataset_cleaned_filtered %>% 
                                       dplyr::select(CodeDépartement, region), 
                                     by = "CodeDépartement")
crime_departement_annee <- crime_departement_annee %>%
  rename(Département = region)

head(crime_departement_annee)

```
Les données étant nettoyées, nous pouvons maintenant réaliser une carte de France pour mieux les visualiser. 

```{r}
map_crime <- map_data("france")
names(crime_departement_annee)[names(crime_departement_annee) == "Département"] <- "region"
crime_departement_annee_filtered <- crime_departement_annee %>%
  filter(annee == 2021)
crime_result_map <- left_join(x = map_crime[,-6], y = crime_departement_annee_filtered)
```

Cette fois, nous allons utiliser un dégradé de couleurs pour les différents départements. Nous avons choisi de filtrer les données pour ne garder que l'année 2021, étant l'année précédant les élections.

```{r}
crime_map_theme <- theme(title = element_text(margin = margin(b = 20, r = 25)), # Ajustement des marges intérieures du titre
                   plot.title = element_text(margin = margin(b = 20, t = 20)), # Ajustement des marges intérieures du titre principal
                   plot.subtitle = element_text(margin = margin(b = 20)), # Ajustement des marges intérieures du sous-titre
                   axis.text.x=element_blank(),
                   axis.text.y=element_blank(),
                   axis.ticks=element_blank(),
                   axis.title.x=element_blank(),
                   axis.title.y=element_blank(),
                   panel.grid.major= element_blank(), 
                   panel.background= element_blank())
ggplot(crime_result_map, aes(long,lat, group = group, fill = taux_crime_par_1000)) +
  geom_polygon() +
  geom_path(color = "black", size = 0.3) + # On ajoute la frontière entre les départements
  coord_map() +
  scale_fill_gradientn(colours = c("yellow","red"), name = "Nombre de crimes (/1000 hab)") +
  labs(x = "", 
       y = "", 
       title = "Nombre de crimes par 1000 habitants par département en 2021", 
       subtitle = "Données via data.gouv") +
  crime_map_theme
```



Nous remarquons ici que le taux de criminalité est le plus élevé dans les départements où se trouvent les villes principales, à savoir la région Parisienne, la Loire-Atlantique, les Bouches-Du-Rhône, le Rhône et le Pas-de-Calais. Maintenant, nous pouvons chercher s'il existe un lien entre la criminalité et les résultats des candidats principaux.

### b. Dataset sur le chômage
Même chose ici. Nous ne gardons que les années de 2016 à 2023, années présentes sur le jeu de données précédent portant sur la criminalité.
Nous réalisons également une moyenne par année, n'ayant pas besoin de l'évolution du taux de criminalité par semestre.
```{r}
dataset_chomage <- read_xls("dataset_chomage.xls")

# Sélection des colonnes de 2016 à 2023
cols_to_keep <- grep("2016$|2017$|2018$|2019$|2020$|2021$|2022$|2023$", names(dataset_chomage), value = TRUE)
cols_to_keep <- c("Code", "Libellé", cols_to_keep)

# Création du nouveau dataframe avec les années dont on a besoin
dataset_chomage_filtered <- dataset_chomage[, cols_to_keep]
cols_to_keep <- grep("T[1-4]_201[6-9]|T[1-4]_202[0-3]", names(dataset_chomage), value = TRUE)

# Calcul de la moyenne du taux de chômage pour chaque année pour chaque département
dataset_chomage_filtered$Moyenne_2016 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2016", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2017 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2017", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2018 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2018", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2019 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2019", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2020 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2020", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2021 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2021", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2022 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2022", names(dataset_chomage_filtered))])
dataset_chomage_filtered$Moyenne_2023 <- rowMeans(dataset_chomage_filtered[, grepl("T[1-4]_2023", names(dataset_chomage_filtered))])

library(dplyr)

# Sélection des colonnes à conserver (code, libellé et moyennes)
cols_to_keep <- c("Code", "Libellé", paste0("Moyenne_", 2016:2023))

# Création d'un nouveau dataframe avec les colonnes sélectionnées
dataset_chomage_filtered <- dataset_chomage_filtered %>%
  dplyr::select(cols_to_keep)
# Suppression des DOM TOM
dataset_chomage_filtered <- dataset_chomage_filtered %>%
  filter(!Code %in% c(971, 972, 973, 974))
names(dataset_chomage_filtered)[names(dataset_chomage_filtered) == "Libellé"] <- "region"
head(dataset_chomage_filtered)
```
Générons maintenant une carte illustrant ces données, comme dans la partie précédente.

```{r}

map_chomage <- map_data("france")
chomage_result_map <- left_join(x = map_chomage[,-6], y = dataset_chomage_filtered)
chomage_map_theme <- theme(title = element_text(margin = margin(b = 20, r = 25)), # Ajustement des marges intérieures du titre
                   plot.title = element_text(margin = margin(b = 20, t = 20)), # Ajustement des marges intérieures du titre principal
                   plot.subtitle = element_text(margin = margin(b = 20)), # Ajustement des marges intérieures du sous-titre
                   axis.text.x=element_blank(),
                   axis.text.y=element_blank(),
                   axis.ticks=element_blank(),
                   axis.title.x=element_blank(),
                   axis.title.y=element_blank(),
                   panel.grid.major= element_blank(), 
                   panel.background= element_blank())
ggplot(chomage_result_map, aes(long,lat, group = group, fill = Moyenne_2021)) +
  geom_polygon() +
  geom_path(color = "black", size = 0.3) + # On ajoute la frontière entre les départements
  coord_map() +
  scale_fill_gradientn(colours=c("blue", "lightgreen"), name = "Taux de chômage (%)") +
  labs(x = "", 
       y = "", 
       title = "Taux de chômage par département en 2021", 
       subtitle = "Données via data.gouv") +
  chomage_map_theme
```
